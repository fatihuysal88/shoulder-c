{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import cv2\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from get_metrics import *\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchnet import meter\n",
    "from torchnet.meter import aucmeter\n",
    "from torch.optim import lr_scheduler\n",
    "from ignite.contrib.metrics import roc_auc\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.datasets.folder import default_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = 'mura_clahe'\n",
    "data_dir = os.path.join(ROOT, 'mura')\n",
    "images_dir = os.path.join(data_dir, 'images')\n",
    "train_dir = os.path.join(data_dir, 'train')\n",
    "val_dir = os.path.join(data_dir, 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_size = 320\n",
    "\n",
    "pretrained_means = [0.485,0.456,0.406]\n",
    "\n",
    "pretrained_stds= [0.229,0.224,0.225]\n",
    "\n",
    "batch_size=8\n",
    "\n",
    "data_transforms = {\n",
    "    \n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((pretrained_size,pretrained_size)),\n",
    "                           transforms.RandomHorizontalFlip(),\n",
    "                           transforms.RandomRotation(5),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((pretrained_size,pretrained_size)),\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize(mean = pretrained_means, \n",
    "                                                std = pretrained_stds)\n",
    "    ]),\n",
    "                   }\n",
    "print(\"Initializing Datasets and Dataloaders...\\n\")\n",
    "# Create training and validation datasets\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'val']}\n",
    "# Create training and validation dataloaders\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True, num_workers=4,pin_memory=True) for x in ['train', 'val']}\n",
    "device = torch.device(\"cuda:0\")\n",
    "dataset_sizes ={x:len(image_datasets[x]) for x in ['train','val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Class names convert to index\n",
    "image_datasets['train'].class_to_idx\n",
    "class_names=image_datasets['train'].classes\n",
    "print(\">>Class Names: {}\\n\".format(image_datasets['train'].classes))\n",
    "print(\">>Class Index: {}\\n\".format(image_datasets['train'].class_to_idx))\n",
    "print(\">>Number of images in training={}\\n\".format(dataset_sizes['train']))\n",
    "print(\">>Number of images in test={}\\n\".format(dataset_sizes['val']))\n",
    "print(\"    Number of steps for training set={}\\n\".format(len(dataloaders['train'])))\n",
    "print(\"    Number of steps for test set={}\\n\".format(len(dataloaders['val']))) \n",
    "# 1:positive #0:negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for class 1\n",
    "student_0=models.resnet34(pretrained=True)\n",
    "student_1=models.densenet201(pretrained=True)\n",
    "#for class 0\n",
    "student_3=models.densenet169(pretrained=True)\n",
    "student_4=models.resnext50_32x4d(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinalNet_ResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpinalNet_ResNet, self).__init__()\n",
    "        self.fc_spinal_layer1 = nn.Sequential(\n",
    "        nn.Linear(256, 256),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer2 = nn.Sequential(\n",
    "        nn.Linear(256+256, 256),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer3 = nn.Sequential(\n",
    "        nn.Linear(256+256, 256),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer4 = nn.Sequential(\n",
    "        nn.Linear(256+256, 256),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_out = nn.Sequential(\n",
    "        nn.Linear(256*4, 2),nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc_spinal_layer1(x[:, 0:256])\n",
    "        x2 = self.fc_spinal_layer2(torch.cat([ x[:,256:2*256], x1], dim=1))\n",
    "        x3 = self.fc_spinal_layer3(torch.cat([ x[:,0:256], x2], dim=1))\n",
    "        x4 = self.fc_spinal_layer4(torch.cat([ x[:,256:2*256], x3], dim=1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinalNet_Dense(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpinalNet_Dense, self).__init__()\n",
    "        self.fc_spinal_layer1 = nn.Sequential(\n",
    "        nn.Dropout(p = 0.5), nn.Linear(960, 240),\n",
    "        nn.BatchNorm1d(240), nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer2 = nn.Sequential(\n",
    "        nn.Dropout(p = 0.5),\n",
    "        nn.Linear(960+240, 240),\n",
    "        nn.BatchNorm1d(240),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer3 = nn.Sequential(\n",
    "        nn.Dropout(p = 0.5),\n",
    "        nn.Linear(960+240, 240),\n",
    "        nn.BatchNorm1d(240),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer4 = nn.Sequential(\n",
    "        nn.Dropout(p = 0.5),\n",
    "        nn.Linear(960+240, 240),\n",
    "        nn.BatchNorm1d(240),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_out = nn.Sequential(\n",
    "        nn.Dropout(p = 0.5),\n",
    "        nn.Linear(240*4, 2),nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        x1 = self.fc_spinal_layer1(x[:, 0:960])\n",
    "        x2 = self.fc_spinal_layer2(torch.cat([ x[:,960:2*960], x1], dim=1))\n",
    "        x3 = self.fc_spinal_layer3(torch.cat([ x[:,0:960], x2], dim=1))\n",
    "        x4 = self.fc_spinal_layer4(torch.cat([ x[:,960:2*960], x3], dim=1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinalNet_ResNext(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(SpinalNet_ResNext, self).__init__()\n",
    "        self.fc_spinal_layer1 = nn.Sequential(\n",
    "        nn.Linear(1024, 20),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer2 = nn.Sequential(\n",
    "        nn.Linear(1024+20, 20),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer3 = nn.Sequential(\n",
    "        nn.Linear(1024+20, 20),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_spinal_layer4 = nn.Sequential(\n",
    "        nn.Linear(1024+20, 20),\n",
    "        nn.ReLU(inplace=True),)\n",
    "        self.fc_out = nn.Sequential(\n",
    "        nn.Linear(20*4, 2),nn.Sigmoid(),)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        x1 = self.fc_spinal_layer1(x[:, 0:1024])\n",
    "        x2 = self.fc_spinal_layer2(torch.cat([ x[:,1024:2*1024], x1], dim=1))\n",
    "        x3 = self.fc_spinal_layer3(torch.cat([ x[:,0:1024], x2], dim=1))\n",
    "        x4 = self.fc_spinal_layer4(torch.cat([ x[:,1024:2*1024], x3], dim=1))\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = torch.cat([x, x3], dim=1)\n",
    "        x = torch.cat([x, x4], dim=1)\n",
    "        x = self.fc_out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_0.fc = SpinalNet_ResNet()\n",
    "student_1.classifier = SpinalNet_Dense()\n",
    "student_3.classifier = nn.Sequential(nn.Linear(1664,2),nn.Sigmoid())\n",
    "student_4.fc = SpinalNet_ResNext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_0.load_state_dict(torch.load(\"./ResNet_34_SP_FC_Clahe_Edge.pth\"))\n",
    "student_1.load_state_dict(torch.load(\"./DenseNet_201_SP_FC_Edge_Clahe.pth\"))\n",
    "student_3.load_state_dict(torch.load(\"./DenseNet_169_FC_Edge_Clahe.pth\"))\n",
    "student_4.load_state_dict(torch.load(\"./ResNext_50_SP_FC_Clahe_Edge.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_0.to(device)\n",
    "student_1.to(device)\n",
    "student_3.to(device)\n",
    "student_4.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_0.eval()\n",
    "student_1.eval()\n",
    "student_3.eval()\n",
    "student_4.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rose(nn.Module):\n",
    "    def __init__(self,nb_classes=2):\n",
    "        super(rose, self).__init__()\n",
    "        \n",
    "        self.modelA = student_0\n",
    "        self.modelB = student_1\n",
    "        self.modelC = student_3\n",
    "        self.modelE = student_4\n",
    "        \n",
    "        self.classifier =nn.Linear(8, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        \n",
    "        outputs_0 = self.modelA(x)\n",
    "        _, predicted_0 =torch.max(outputs_0.data, 1) \n",
    "            \n",
    "        outputs_1 = self.modelB(x)\n",
    "        _, predicted_1 =torch.max(outputs_1.data, 1) \n",
    "            \n",
    "        outputs_3 = self.modelC(x)\n",
    "        _, predicted_3 =torch.max(outputs_3.data, 1) \n",
    "            \n",
    "        outputs_4 = self.modelE(x)\n",
    "        _, predicted_4 =torch.max(outputs_4.data, 1)           \n",
    "        \n",
    "        x = torch.cat((outputs_0, outputs_1,outputs_3,outputs_4), dim=1) \n",
    "                \n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_ensemble=rose()\n",
    "sub_ensemble.to(device)\n",
    "sub_ensemble.load_state_dict(torch.load(\"./sub_ensemble.pth\"))\n",
    "sub_ensemble.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric.test_model_el2(student_0,student_1,sub_ensemble,student_3,device,dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals, predictions = get_metric.test_label_predictions_el2(student_0,student_1,sub_ensemble,student_3,device,dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric.get_classification_report(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric.get_confusion_matrix(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric.get_cohen_kappa(actuals, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metric.get_roc_curves_el2(student_0,student_1,sub_ensemble,student_3, device,  dataloaders['val'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
